{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0beb8608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "215d838a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('50_Startups.csv')\n",
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "06e7d08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101913.08 110594.11 229160.95 'Florida']\n"
     ]
    }
   ],
   "source": [
    "print(X[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c0629802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192261.83 191792.06 191050.39 182901.99 166187.94 156991.12 156122.51\n",
      " 155752.6  152211.77 149759.96 146121.95 144259.4  141585.52 134307.35\n",
      " 132602.65 129917.04 126992.93 125370.37 124266.9  122776.86 118474.03\n",
      " 111313.02 110352.25 108733.99 108552.04 107404.34 105733.54 105008.31\n",
      " 103282.38 101004.64  99937.59  97483.56  97427.84  96778.92  96712.8\n",
      "  96479.51  90708.19  89949.14  81229.06  81005.76  78239.91  77798.83\n",
      "  71498.49  69758.98  65200.33  64926.08  49490.75  42559.73  35673.41\n",
      "  14681.4 ]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dad671",
   "metadata": {},
   "source": [
    "Kategorik verileri encode etme (OneHot yöntemi ile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "dfea28b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "08576433",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[3])],remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "aeb23581",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1aa1752b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0 1.0 0.0 101913.08 110594.11 229160.95]\n"
     ]
    }
   ],
   "source": [
    "print(X[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecb8fe3",
   "metadata": {},
   "source": [
    "Dummy Variable tuzağından kurtulma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "51e3af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3e829072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "cf553aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "18cc241c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b2ac95b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_without_backward_elimination = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "59d3c178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103015.2  103282.38]\n",
      " [132582.28 144259.4 ]\n",
      " [132447.74 146121.95]\n",
      " [ 71976.1   77798.83]\n",
      " [178537.48 191050.39]\n",
      " [116161.24 105008.31]\n",
      " [ 67851.69  81229.06]\n",
      " [ 98791.73  97483.56]\n",
      " [113969.44 110352.25]\n",
      " [167921.07 166187.94]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred_without_backward_elimination.reshape(len(y_pred_without_backward_elimination),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3487ea14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103015.2  132582.28 132447.74  71976.1  178537.48 116161.24  67851.69\n",
      "  98791.73 113969.44 167921.07]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d31366",
   "metadata": {},
   "source": [
    "Backward Eliminarion Yöntemi İle Optimal Feature Tablosunu bulma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4ccb4d",
   "metadata": {},
   "source": [
    "Backward Elimination Yöntemi P > SL için feature'i feature tablosundan çıkararak ilerleyen iteratif bir yöntemdir\n",
    "Her seferinde 1 P > SL (SL = 0.05) olan bir feature feature tablosundan çıkarılır ve bütün model tekrardan eğitilir.\n",
    "Model eğitimi sonucunda verilere tekrardan bakılır ve sonucuda hala P > SL varsa o feature çıkarılıp model tekrardan eğitilir\n",
    "Tablonunun içinde P > SL verisine sahip olan feature kalmayana kadar devam edilir\n",
    "Bu featureler temizlendikten sonra optimum feature tablosuna ulaşılmış kabul edilir.\n",
    "P > SL sıralaması için seçim şeklide en yüksek p'ye sahip olan en önce çıkarılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fbc0e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bc7fc610",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(arr = np.ones((50, 1)).astype(int), values = X, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a00f62f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0.0 1.0 165349.2 136897.8 471784.1]\n",
      " [1 0.0 0.0 162597.7 151377.59 443898.53]\n",
      " [1 1.0 0.0 153441.51 101145.55 407934.54]\n",
      " [1 0.0 1.0 144372.41 118671.85 383199.62]\n",
      " [1 1.0 0.0 142107.34 91391.77 366168.42]\n",
      " [1 0.0 1.0 131876.9 99814.71 362861.36]\n",
      " [1 0.0 0.0 134615.46 147198.87 127716.82]\n",
      " [1 1.0 0.0 130298.13 145530.06 323876.68]\n",
      " [1 0.0 1.0 120542.52 148718.95 311613.29]\n",
      " [1 0.0 0.0 123334.88 108679.17 304981.62]\n",
      " [1 1.0 0.0 101913.08 110594.11 229160.95]\n",
      " [1 0.0 0.0 100671.96 91790.61 249744.55]\n",
      " [1 1.0 0.0 93863.75 127320.38 249839.44]\n",
      " [1 0.0 0.0 91992.39 135495.07 252664.93]\n",
      " [1 1.0 0.0 119943.24 156547.42 256512.92]\n",
      " [1 0.0 1.0 114523.61 122616.84 261776.23]\n",
      " [1 0.0 0.0 78013.11 121597.55 264346.06]\n",
      " [1 0.0 1.0 94657.16 145077.58 282574.31]\n",
      " [1 1.0 0.0 91749.16 114175.79 294919.57]\n",
      " [1 0.0 1.0 86419.7 153514.11 0.0]\n",
      " [1 0.0 0.0 76253.86 113867.3 298664.47]\n",
      " [1 0.0 1.0 78389.47 153773.43 299737.29]\n",
      " [1 1.0 0.0 73994.56 122782.75 303319.26]\n",
      " [1 1.0 0.0 67532.53 105751.03 304768.73]\n",
      " [1 0.0 1.0 77044.01 99281.34 140574.81]\n",
      " [1 0.0 0.0 64664.71 139553.16 137962.62]\n",
      " [1 1.0 0.0 75328.87 144135.98 134050.07]\n",
      " [1 0.0 1.0 72107.6 127864.55 353183.81]\n",
      " [1 1.0 0.0 66051.52 182645.56 118148.2]\n",
      " [1 0.0 1.0 65605.48 153032.06 107138.38]\n",
      " [1 1.0 0.0 61994.48 115641.28 91131.24]\n",
      " [1 0.0 1.0 61136.38 152701.92 88218.23]\n",
      " [1 0.0 0.0 63408.86 129219.61 46085.25]\n",
      " [1 1.0 0.0 55493.95 103057.49 214634.81]\n",
      " [1 0.0 0.0 46426.07 157693.92 210797.67]\n",
      " [1 0.0 1.0 46014.02 85047.44 205517.64]\n",
      " [1 1.0 0.0 28663.76 127056.21 201126.82]\n",
      " [1 0.0 0.0 44069.95 51283.14 197029.42]\n",
      " [1 0.0 1.0 20229.59 65947.93 185265.1]\n",
      " [1 0.0 0.0 38558.51 82982.09 174999.3]\n",
      " [1 0.0 0.0 28754.33 118546.05 172795.67]\n",
      " [1 1.0 0.0 27892.92 84710.77 164470.71]\n",
      " [1 0.0 0.0 23640.93 96189.63 148001.11]\n",
      " [1 0.0 1.0 15505.73 127382.3 35534.17]\n",
      " [1 0.0 0.0 22177.74 154806.14 28334.72]\n",
      " [1 0.0 1.0 1000.23 124153.04 1903.93]\n",
      " [1 1.0 0.0 1315.46 115816.21 297114.46]\n",
      " [1 0.0 0.0 0.0 135426.92 0.0]\n",
      " [1 0.0 1.0 542.05 51743.15 0.0]\n",
      " [1 0.0 0.0 0.0 116983.8 45173.06]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6b1dc8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt = X[:,[0,1,2,4,5]]\n",
    "X_opt = X_opt.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "518012a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00e+00 0.00e+00 1.00e+00 1.37e+05 4.72e+05]\n",
      " [1.00e+00 0.00e+00 0.00e+00 1.51e+05 4.44e+05]\n",
      " [1.00e+00 1.00e+00 0.00e+00 1.01e+05 4.08e+05]\n",
      " [1.00e+00 0.00e+00 1.00e+00 1.19e+05 3.83e+05]\n",
      " [1.00e+00 1.00e+00 0.00e+00 9.14e+04 3.66e+05]\n",
      " [1.00e+00 0.00e+00 1.00e+00 9.98e+04 3.63e+05]\n",
      " [1.00e+00 0.00e+00 0.00e+00 1.47e+05 1.28e+05]\n",
      " [1.00e+00 1.00e+00 0.00e+00 1.46e+05 3.24e+05]\n",
      " [1.00e+00 0.00e+00 1.00e+00 1.49e+05 3.12e+05]\n",
      " [1.00e+00 0.00e+00 0.00e+00 1.09e+05 3.05e+05]\n",
      " [1.00e+00 1.00e+00 0.00e+00 1.11e+05 2.29e+05]\n",
      " [1.00e+00 0.00e+00 0.00e+00 9.18e+04 2.50e+05]\n",
      " [1.00e+00 1.00e+00 0.00e+00 1.27e+05 2.50e+05]\n",
      " [1.00e+00 0.00e+00 0.00e+00 1.35e+05 2.53e+05]\n",
      " [1.00e+00 1.00e+00 0.00e+00 1.57e+05 2.57e+05]\n",
      " [1.00e+00 0.00e+00 1.00e+00 1.23e+05 2.62e+05]\n",
      " [1.00e+00 0.00e+00 0.00e+00 1.22e+05 2.64e+05]\n",
      " [1.00e+00 0.00e+00 1.00e+00 1.45e+05 2.83e+05]\n",
      " [1.00e+00 1.00e+00 0.00e+00 1.14e+05 2.95e+05]\n",
      " [1.00e+00 0.00e+00 1.00e+00 1.54e+05 0.00e+00]\n",
      " [1.00e+00 0.00e+00 0.00e+00 1.14e+05 2.99e+05]\n",
      " [1.00e+00 0.00e+00 1.00e+00 1.54e+05 3.00e+05]\n",
      " [1.00e+00 1.00e+00 0.00e+00 1.23e+05 3.03e+05]\n",
      " [1.00e+00 1.00e+00 0.00e+00 1.06e+05 3.05e+05]\n",
      " [1.00e+00 0.00e+00 1.00e+00 9.93e+04 1.41e+05]\n",
      " [1.00e+00 0.00e+00 0.00e+00 1.40e+05 1.38e+05]\n",
      " [1.00e+00 1.00e+00 0.00e+00 1.44e+05 1.34e+05]\n",
      " [1.00e+00 0.00e+00 1.00e+00 1.28e+05 3.53e+05]\n",
      " [1.00e+00 1.00e+00 0.00e+00 1.83e+05 1.18e+05]\n",
      " [1.00e+00 0.00e+00 1.00e+00 1.53e+05 1.07e+05]\n",
      " [1.00e+00 1.00e+00 0.00e+00 1.16e+05 9.11e+04]\n",
      " [1.00e+00 0.00e+00 1.00e+00 1.53e+05 8.82e+04]\n",
      " [1.00e+00 0.00e+00 0.00e+00 1.29e+05 4.61e+04]\n",
      " [1.00e+00 1.00e+00 0.00e+00 1.03e+05 2.15e+05]\n",
      " [1.00e+00 0.00e+00 0.00e+00 1.58e+05 2.11e+05]\n",
      " [1.00e+00 0.00e+00 1.00e+00 8.50e+04 2.06e+05]\n",
      " [1.00e+00 1.00e+00 0.00e+00 1.27e+05 2.01e+05]\n",
      " [1.00e+00 0.00e+00 0.00e+00 5.13e+04 1.97e+05]\n",
      " [1.00e+00 0.00e+00 1.00e+00 6.59e+04 1.85e+05]\n",
      " [1.00e+00 0.00e+00 0.00e+00 8.30e+04 1.75e+05]\n",
      " [1.00e+00 0.00e+00 0.00e+00 1.19e+05 1.73e+05]\n",
      " [1.00e+00 1.00e+00 0.00e+00 8.47e+04 1.64e+05]\n",
      " [1.00e+00 0.00e+00 0.00e+00 9.62e+04 1.48e+05]\n",
      " [1.00e+00 0.00e+00 1.00e+00 1.27e+05 3.55e+04]\n",
      " [1.00e+00 0.00e+00 0.00e+00 1.55e+05 2.83e+04]\n",
      " [1.00e+00 0.00e+00 1.00e+00 1.24e+05 1.90e+03]\n",
      " [1.00e+00 1.00e+00 0.00e+00 1.16e+05 2.97e+05]\n",
      " [1.00e+00 0.00e+00 0.00e+00 1.35e+05 0.00e+00]\n",
      " [1.00e+00 0.00e+00 1.00e+00 5.17e+04 0.00e+00]\n",
      " [1.00e+00 0.00e+00 0.00e+00 1.17e+05 4.52e+04]]\n"
     ]
    }
   ],
   "source": [
    "print(X_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0eac45ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_OLS = sm.OLS(endog=y,exog=X_opt).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "141afc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.613</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   17.83</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 24 Oct 2023</td> <th>  Prob (F-statistic):</th> <td>7.78e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:01:23</td>     <th>  Log-Likelihood:    </th> <td> -576.91</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1164.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1173.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 1.903e+04</td> <td> 1.84e+04</td> <td>    1.033</td> <td> 0.307</td> <td>-1.81e+04</td> <td> 5.61e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-1703.7028</td> <td> 9337.989</td> <td>   -0.182</td> <td> 0.856</td> <td>-2.05e+04</td> <td> 1.71e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td> 3875.7625</td> <td> 9002.603</td> <td>    0.431</td> <td> 0.669</td> <td>-1.43e+04</td> <td>  2.2e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.3239</td> <td>    0.133</td> <td>    2.426</td> <td> 0.019</td> <td>    0.055</td> <td>    0.593</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.2507</td> <td>    0.031</td> <td>    7.997</td> <td> 0.000</td> <td>    0.188</td> <td>    0.314</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 5.729</td> <th>  Durbin-Watson:     </th> <td>   1.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.057</td> <th>  Jarque-Bera (JB):  </th> <td>   5.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.461</td> <th>  Prob(JB):          </th> <td>  0.0689</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.311</td> <th>  Cond. No.          </th> <td>1.34e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.34e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.613\n",
       "Model:                            OLS   Adj. R-squared:                  0.579\n",
       "Method:                 Least Squares   F-statistic:                     17.83\n",
       "Date:                Tue, 24 Oct 2023   Prob (F-statistic):           7.78e-09\n",
       "Time:                        22:01:23   Log-Likelihood:                -576.91\n",
       "No. Observations:                  50   AIC:                             1164.\n",
       "Df Residuals:                      45   BIC:                             1173.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       1.903e+04   1.84e+04      1.033      0.307   -1.81e+04    5.61e+04\n",
       "x1         -1703.7028   9337.989     -0.182      0.856   -2.05e+04    1.71e+04\n",
       "x2          3875.7625   9002.603      0.431      0.669   -1.43e+04     2.2e+04\n",
       "x3             0.3239      0.133      2.426      0.019       0.055       0.593\n",
       "x4             0.2507      0.031      7.997      0.000       0.188       0.314\n",
       "==============================================================================\n",
       "Omnibus:                        5.729   Durbin-Watson:                   1.266\n",
       "Prob(Omnibus):                  0.057   Jarque-Bera (JB):                5.349\n",
       "Skew:                          -0.461   Prob(JB):                       0.0689\n",
       "Kurtosis:                       4.311   Cond. No.                     1.34e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.34e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9764ac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt = X[:,[0,2,3,4,5]]\n",
    "X_opt = X_opt.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "72c6b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "bba18ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   217.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 24 Oct 2023</td> <th>  Prob (F-statistic):</th> <td>8.50e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:01:27</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1061.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1070.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.018e+04</td> <td> 6747.623</td> <td>    7.437</td> <td> 0.000</td> <td> 3.66e+04</td> <td> 6.38e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -136.5042</td> <td> 2801.719</td> <td>   -0.049</td> <td> 0.961</td> <td>-5779.456</td> <td> 5506.447</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.8059</td> <td>    0.046</td> <td>   17.571</td> <td> 0.000</td> <td>    0.714</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0269</td> <td>    0.052</td> <td>   -0.521</td> <td> 0.605</td> <td>   -0.131</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0271</td> <td>    0.017</td> <td>    1.625</td> <td> 0.111</td> <td>   -0.007</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.892</td> <th>  Durbin-Watson:     </th> <td>   1.284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.665</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>1.97e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.608</td> <th>  Cond. No.          </th> <td>1.43e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.43e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.946\n",
       "Method:                 Least Squares   F-statistic:                     217.2\n",
       "Date:                Tue, 24 Oct 2023   Prob (F-statistic):           8.50e-29\n",
       "Time:                        22:01:27   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1061.\n",
       "Df Residuals:                      45   BIC:                             1070.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.018e+04   6747.623      7.437      0.000    3.66e+04    6.38e+04\n",
       "x1          -136.5042   2801.719     -0.049      0.961   -5779.456    5506.447\n",
       "x2             0.8059      0.046     17.571      0.000       0.714       0.898\n",
       "x3            -0.0269      0.052     -0.521      0.605      -0.131       0.077\n",
       "x4             0.0271      0.017      1.625      0.111      -0.007       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.892   Durbin-Watson:                   1.284\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.665\n",
       "Skew:                          -0.949   Prob(JB):                     1.97e-05\n",
       "Kurtosis:                       5.608   Cond. No.                     1.43e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.43e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "094f32b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt = X[:,[0,3,4,5]]\n",
    "X_opt = X_opt.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0d9fb500",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d5fbea30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   296.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 24 Oct 2023</td> <th>  Prob (F-statistic):</th> <td>4.53e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:01:32</td>     <th>  Log-Likelihood:    </th> <td> -525.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1066.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.012e+04</td> <td> 6572.353</td> <td>    7.626</td> <td> 0.000</td> <td> 3.69e+04</td> <td> 6.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8057</td> <td>    0.045</td> <td>   17.846</td> <td> 0.000</td> <td>    0.715</td> <td>    0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0268</td> <td>    0.051</td> <td>   -0.526</td> <td> 0.602</td> <td>   -0.130</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0272</td> <td>    0.016</td> <td>    1.655</td> <td> 0.105</td> <td>   -0.006</td> <td>    0.060</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.838</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>2.21e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.586</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     296.0\n",
       "Date:                Tue, 24 Oct 2023   Prob (F-statistic):           4.53e-30\n",
       "Time:                        22:01:32   Log-Likelihood:                -525.39\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      46   BIC:                             1066.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.012e+04   6572.353      7.626      0.000    3.69e+04    6.34e+04\n",
       "x1             0.8057      0.045     17.846      0.000       0.715       0.897\n",
       "x2            -0.0268      0.051     -0.526      0.602      -0.130       0.076\n",
       "x3             0.0272      0.016      1.655      0.105      -0.006       0.060\n",
       "==============================================================================\n",
       "Omnibus:                       14.838   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.442\n",
       "Skew:                          -0.949   Prob(JB):                     2.21e-05\n",
       "Kurtosis:                       5.586   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "aab59343",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt = X[:,[0,3,5]]\n",
    "X_opt = X_opt.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b5c7261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e6e0b157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 24 Oct 2023</td> <th>  Prob (F-statistic):</th> <td>2.16e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:01:38</td>     <th>  Log-Likelihood:    </th> <td> -525.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1057.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.698e+04</td> <td> 2689.933</td> <td>   17.464</td> <td> 0.000</td> <td> 4.16e+04</td> <td> 5.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7966</td> <td>    0.041</td> <td>   19.266</td> <td> 0.000</td> <td>    0.713</td> <td>    0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0299</td> <td>    0.016</td> <td>    1.927</td> <td> 0.060</td> <td>   -0.001</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.677</td> <th>  Durbin-Watson:     </th> <td>   1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.939</td> <th>  Prob(JB):          </th> <td>2.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.575</td> <th>  Cond. No.          </th> <td>5.32e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.32e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     450.8\n",
       "Date:                Tue, 24 Oct 2023   Prob (F-statistic):           2.16e-31\n",
       "Time:                        22:01:38   Log-Likelihood:                -525.54\n",
       "No. Observations:                  50   AIC:                             1057.\n",
       "Df Residuals:                      47   BIC:                             1063.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\n",
       "x1             0.7966      0.041     19.266      0.000       0.713       0.880\n",
       "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
       "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
       "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48b6afd",
   "metadata": {},
   "source": [
    "Nihayetinde P > SL kalmadığından X_opt içi değerimiz aşağıdaki gibidir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "38a46652",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt = X[:,[0,3,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1936efb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 165349.2 471784.1]\n",
      " [1 162597.7 443898.53]\n",
      " [1 153441.51 407934.54]\n",
      " [1 144372.41 383199.62]\n",
      " [1 142107.34 366168.42]\n",
      " [1 131876.9 362861.36]\n",
      " [1 134615.46 127716.82]\n",
      " [1 130298.13 323876.68]\n",
      " [1 120542.52 311613.29]\n",
      " [1 123334.88 304981.62]\n",
      " [1 101913.08 229160.95]\n",
      " [1 100671.96 249744.55]\n",
      " [1 93863.75 249839.44]\n",
      " [1 91992.39 252664.93]\n",
      " [1 119943.24 256512.92]\n",
      " [1 114523.61 261776.23]\n",
      " [1 78013.11 264346.06]\n",
      " [1 94657.16 282574.31]\n",
      " [1 91749.16 294919.57]\n",
      " [1 86419.7 0.0]\n",
      " [1 76253.86 298664.47]\n",
      " [1 78389.47 299737.29]\n",
      " [1 73994.56 303319.26]\n",
      " [1 67532.53 304768.73]\n",
      " [1 77044.01 140574.81]\n",
      " [1 64664.71 137962.62]\n",
      " [1 75328.87 134050.07]\n",
      " [1 72107.6 353183.81]\n",
      " [1 66051.52 118148.2]\n",
      " [1 65605.48 107138.38]\n",
      " [1 61994.48 91131.24]\n",
      " [1 61136.38 88218.23]\n",
      " [1 63408.86 46085.25]\n",
      " [1 55493.95 214634.81]\n",
      " [1 46426.07 210797.67]\n",
      " [1 46014.02 205517.64]\n",
      " [1 28663.76 201126.82]\n",
      " [1 44069.95 197029.42]\n",
      " [1 20229.59 185265.1]\n",
      " [1 38558.51 174999.3]\n",
      " [1 28754.33 172795.67]\n",
      " [1 27892.92 164470.71]\n",
      " [1 23640.93 148001.11]\n",
      " [1 15505.73 35534.17]\n",
      " [1 22177.74 28334.72]\n",
      " [1 1000.23 1903.93]\n",
      " [1 1315.46 297114.46]\n",
      " [1 0.0 0.0]\n",
      " [1 542.05 0.0]\n",
      " [1 0.0 45173.06]]\n"
     ]
    }
   ],
   "source": [
    "print(X_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6bb00fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_opt,X_test_opt,y_train_opt,y_test_opt = train_test_split(X_opt,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c613230c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train_opt,y_train_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0670e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_with_backward_elimination = regressor.predict(X_test_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "86cc8604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Backward Eliminitaion\n",
      "[[102284.65 103282.38]\n",
      " [133873.92 144259.4 ]\n",
      " [134182.15 146121.95]\n",
      " [ 73701.11  77798.83]\n",
      " [180642.25 191050.39]\n",
      " [114717.25 105008.31]\n",
      " [ 68335.08  81229.06]\n",
      " [ 97433.46  97483.56]\n",
      " [114580.92 110352.25]\n",
      " [170343.32 166187.94]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "print(\"With Backward Eliminitaion\")\n",
    "print(np.concatenate((y_pred_with_backward_elimination.reshape(len(y_pred_with_backward_elimination),1), y_test_opt.reshape(len(y_test_opt),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9ec0e647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Backward Elimination\n",
      "[[103015.2  103282.38]\n",
      " [132582.28 144259.4 ]\n",
      " [132447.74 146121.95]\n",
      " [ 71976.1   77798.83]\n",
      " [178537.48 191050.39]\n",
      " [116161.24 105008.31]\n",
      " [ 67851.69  81229.06]\n",
      " [ 98791.73  97483.56]\n",
      " [113969.44 110352.25]\n",
      " [167921.07 166187.94]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "print(\"Without Backward Elimination\")\n",
    "print(np.concatenate((y_pred_without_backward_elimination.reshape(len(y_pred_without_backward_elimination),1), y_test.reshape(len(y_test),1)),1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
